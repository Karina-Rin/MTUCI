{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **Лабораторная работа 1**\n",
    "\n",
    "***\n",
    "__Алгоритм обучения методом градиентного спуска__\n",
    "***"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Импортование необходимых модулей\n",
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Загрузка и подготовка данных MNIST\n",
    "\"\"\"Шаг 1: Подготовка обучающей выборки.\"\"\"\n",
    "mnist = tf.keras.datasets.mnist\n",
    "(x_train, y_train), (x_test, y_test) = mnist.load_data()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Нормализация данных\n",
    "x_train = x_train / 255.0\n",
    "x_test = x_test / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование меток в категориальный формат\n",
    "num_classes = 10\n",
    "y_train = np.eye(num_classes)[y_train]\n",
    "y_test = np.eye(num_classes)[y_test]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Преобразование изображений в векторы\n",
    "x_train = x_train.reshape(x_train.shape[0], -1)\n",
    "x_test = x_test.reshape(x_test.shape[0], -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Используем БД MNIST.\n",
    "- Изображения представляют собой одну цифру в диапазоне от 0 до 9, значения пикселей нормализованы к диапазону от 0 до 1.\n",
    "- Метки классов преобразованы в формат one-hot encoding (для задач многоцелевого распознавания)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Perceptron:\n",
    "    def __init__(self, input_dim, output_dim, learning_rate=0.1):\n",
    "        \"\"\"Шаг 2: Инициализация персептрона с заданными размерами входа и выхода.\n",
    "        \n",
    "        Args:\n",
    "            input_dim (int): Размерность входных данных.\n",
    "            output_dim (int): Количество выходных нейронов.\n",
    "            learning_rate (float): Скорость обучения.\n",
    "        \"\"\"\n",
    "        self.weights = np.random.randn(input_dim, output_dim) * 0.01\n",
    "        self.biases = np.random.randn(output_dim) * 0.01\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "    def sigmoid(self, x):\n",
    "        \"\"\"Сигмоидальная функция активации.\n",
    "        \n",
    "        Args:\n",
    "            x (numpy.ndarray): Входные данные.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: Выходные данные после применения сигмоидальной функции.\n",
    "        \"\"\"\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "\n",
    "    def sigmoid_derivative(self, y):\n",
    "        \"\"\"Производная сигмоидальной функции.\n",
    "        \n",
    "        Args:\n",
    "            y (numpy.ndarray): Выходные данные после применения сигмоидальной функции.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: Производная сигмоидальной функции.\n",
    "        \"\"\"\n",
    "        return y * (1 - y)\n",
    "\n",
    "    def forward(self, X):\n",
    "        \"\"\"Шаг 5: Вычисление выхода нейронов.\n",
    "        \n",
    "        Args:\n",
    "            X (numpy.ndarray): Входные данные.\n",
    "        \n",
    "        Returns:\n",
    "            numpy.ndarray: Выход нейронов.\n",
    "        \"\"\"\n",
    "        return self.sigmoid(np.dot(X, self.weights) + self.biases)\n",
    "\n",
    "    def train(self, x_train, y_train, epochs, threshold=1e-3):\n",
    "        \"\"\"Шаг 3: Обучение персептрона с использованием градиентного спуска.\n",
    "        \n",
    "        Args:\n",
    "            x_train (numpy.ndarray): Обучающие данные.\n",
    "            y_train (numpy.ndarray): Метки классов для обучающих данных.\n",
    "            epochs (int): Количество эпох для обучения.\n",
    "            threshold (float): Порог для остановки обучения.\n",
    "        \"\"\"\n",
    "        for epoch in range(epochs):\n",
    "            total_error = 0\n",
    "            weight_updates = np.zeros_like(self.weights)\n",
    "            bias_updates = np.zeros_like(self.biases)\n",
    "\n",
    "            for i in range(x_train.shape[0]):\n",
    "                \"\"\"Шаг 4: Обработка обучающей выборки\"\"\"\n",
    "                X, D = x_train[i:i + 1], y_train[i:i + 1]\n",
    "\n",
    "                \"\"\"Шаг 5: Вычисление взвешенной суммы входных сигналов и выходного сигнала на основании функции активации\"\"\"\n",
    "                Y = self.forward(X)\n",
    "\n",
    "                \"\"\"Шаг 6: Вычисление ошибки для текущего обучающего вектора\"\"\"\n",
    "                error = D - Y\n",
    "                total_error += np.sum(error**2) / 2\n",
    "                delta = error * self.sigmoid_derivative(Y)\n",
    "\n",
    "                \"\"\"Шаг 7: Посчет величины коррекции синаптических весов нейрона и нейронных смещений\"\"\"\n",
    "                weight_updates += np.outer(X.T, delta)\n",
    "                bias_updates += delta.flatten()\n",
    "\n",
    "            \"\"\"Шаг 9: Коррекция синаптических весов\"\"\"\n",
    "            self.weights += self.learning_rate * weight_updates / x_train.shape[0]\n",
    "            self.biases += self.learning_rate * bias_updates / x_train.shape[0]\n",
    "            total_error /= x_train.shape[0]\n",
    "\n",
    "            \"\"\"Шаг 8: Проверка критерия останова обучения\"\"\"\n",
    "            if total_error < threshold:\n",
    "                print(f'Прерывание обучения в эпоху {epoch + 1} из-за низкой погрешности: {total_error:.4f}')\n",
    "                break\n",
    "            print(f'Эпоха {epoch + 1}/{epochs}, Ошибка: {total_error:.4f}')\n",
    "\n",
    "    def evaluate(self, x_test, y_test):\n",
    "        \"\"\"Оценка точности персептрона на тестовых данных.\"\n",
    "        \n",
    "        Args:\n",
    "            x_test (numpy.ndarray): Входные данные для тестирования.\n",
    "            y_test (numpy.ndarray): Желаемые выходные данные для тестирования.\n",
    "        \n",
    "        Returns:\n",
    "            float: Точность модели на тестовых данных.\n",
    "        \"\"\"\n",
    "        predictions = np.argmax(self.forward(x_test), axis=1)\n",
    "        return np.mean(predictions == np.argmax(y_test, axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Параметры персептрона\n",
    "perceptron = Perceptron(input_dim=x_train.shape[1], output_dim=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 184,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Эпоха 1/25, Ошибка: 1.2505\n",
      "Эпоха 2/25, Ошибка: 0.9321\n",
      "Эпоха 3/25, Ошибка: 0.7604\n",
      "Эпоха 4/25, Ошибка: 0.6655\n",
      "Эпоха 5/25, Ошибка: 0.6081\n",
      "Эпоха 6/25, Ошибка: 0.5704\n",
      "Эпоха 7/25, Ошибка: 0.5440\n",
      "Эпоха 8/25, Ошибка: 0.5245\n",
      "Эпоха 9/25, Ошибка: 0.5096\n",
      "Эпоха 10/25, Ошибка: 0.4977\n",
      "Эпоха 11/25, Ошибка: 0.4881\n",
      "Эпоха 12/25, Ошибка: 0.4801\n",
      "Эпоха 13/25, Ошибка: 0.4732\n",
      "Эпоха 14/25, Ошибка: 0.4673\n",
      "Эпоха 15/25, Ошибка: 0.4621\n",
      "Эпоха 16/25, Ошибка: 0.4575\n",
      "Эпоха 17/25, Ошибка: 0.4533\n",
      "Эпоха 18/25, Ошибка: 0.4495\n",
      "Эпоха 19/25, Ошибка: 0.4461\n",
      "Эпоха 20/25, Ошибка: 0.4428\n",
      "Эпоха 21/25, Ошибка: 0.4398\n",
      "Эпоха 22/25, Ошибка: 0.4370\n",
      "Эпоха 23/25, Ошибка: 0.4343\n",
      "Эпоха 24/25, Ошибка: 0.4317\n",
      "Эпоха 25/25, Ошибка: 0.4292\n"
     ]
    }
   ],
   "source": [
    "# Обучение персептрона\n",
    "perceptron.train(x_train, y_train, epochs=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Финальная точность: 0.6478\n"
     ]
    }
   ],
   "source": [
    "# Финальная оценка модели на тестовых данных\n",
    "final_accuracy = perceptron.evaluate(x_test, y_test)\n",
    "print(f'Финальная точность: {final_accuracy:.4f}')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
